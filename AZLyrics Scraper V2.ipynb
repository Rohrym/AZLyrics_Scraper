{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7eb1f1f",
   "metadata": {},
   "source": [
    "# AZLyrics Scraper\n",
    "\n",
    "With this code you could scrape individual lyrics pages or whole artist pages for some of their basic data. First we start by importing the relevant libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20aa346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d57df9",
   "metadata": {},
   "source": [
    "Then we make functions to retrieve the urls from the web and look for certain elements within the webpages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7599e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_page(url):\n",
    "    with requests.get(url) as f:\n",
    "        page = f.text\n",
    "    return page\n",
    "\n",
    "def get_element_text(element):\n",
    "    try:\n",
    "        return element.text.strip()\n",
    "    except AttributeError as e:                     \n",
    "        print('Element not found, error: {}'.format(e), file=sys.stderr)\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccfc0b3",
   "metadata": {},
   "source": [
    "## Getting the individual lyrics\n",
    "We proceed to make a function to get the basic information from each song on a songpage from AZLyrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84924e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_song_info(url):\n",
    "    song_page = BeautifulSoup(load_page(url), 'lxml')                  \n",
    "    interesting_html = song_page.find(class_='container main-page')    \n",
    "    if not interesting_html:\n",
    "        print('No information availible for song at {}'.format(url), file=sys.stderr)\n",
    "        return {}                                                      \n",
    "    album = get_element_text(interesting_html.find(class_='songinalbum_title'))[8:-8]\n",
    "    album_released = get_element_text(interesting_html.find(class_='songinalbum_title'))[-5:-1]\n",
    "    credits = get_element_text(interesting_html.find('small'))[11:] \n",
    "    lyrics = get_element_text(interesting_html.find('div', {'class':None}))\n",
    "    return {'album': album, 'album release': album_released,'credits': credits, 'lyrics': lyrics}                      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d2e4a4",
   "metadata": {},
   "source": [
    "The previous functions can be tested by using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d9c4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_url = 'https://www.azlyrics.com/lyrics/genesis/wherethesourturnstosweet.html' #you should be able to replace this link with that of your favorite song\n",
    "song_info = get_song_info(song_url)\n",
    "for key, value in song_info.items():\n",
    "    if key == 'lyrics': #you can replace 'lyrics' with any one of the keys from the dictionary we just made\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd14e23d",
   "metadata": {},
   "source": [
    "## Getting all artist songs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e06fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_songs(url):\n",
    "    index_page = BeautifulSoup(load_page(url), 'lxml')        \n",
    "    items = index_page.find(id=\"listAlbum\")                   \n",
    "    if not items:                                             \n",
    "        print('Something went wrong!', file=sys.stderr)\n",
    "        sys.exit()\n",
    "    data = []\n",
    "    for row in items.find_all(class_= 'listalbum-item'):          \n",
    "        song = get_element_text(row.find('a'))\n",
    "        link = row.find('a').get('href')\n",
    "        link = 'https://www.azlyrics.com/' + str(link)\n",
    "        data.append({    \n",
    "                         'song': song,\n",
    "                         'link': link,\n",
    "                        })\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55a24f3",
   "metadata": {},
   "source": [
    "## Scraping\n",
    "\n",
    "The following code scrapes AZLyrics for the data for all the given artist's songs. This may take a while depending on the amount of songs released by the artist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c49b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_url = 'https://www.azlyrics.com/g/genesis.html' #replace the link with the azlyrics link to the band you  want to scrape\n",
    "song_data = get_songs(index_url)                      \n",
    "for row in song_data:\n",
    "    print('Scraping info on {}.'.format(row['song'])) #can be useful for debugging\n",
    "    url = row['link']\n",
    "    song_info = get_song_info(url)                    \n",
    "    for key, value in song_info.items():\n",
    "        row[key] = value\n",
    "    time.sleep(random.uniform(4,16))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8942ff6",
   "metadata": {},
   "source": [
    "## Writing data into CSV\n",
    "\n",
    "In this last part we will write down the data we have just scraped in a csv file and convert it to a table using the pandas module in python. From this dataframe we could acces the data easily and perform operations on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55188219",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('songs.csv', 'w', encoding='utf-8') as f:       \n",
    "    fieldnames=['song', 'album', 'album release', 'credits', 'lyrics']\n",
    "    writer = csv.DictWriter(f,\n",
    "                            delimiter=',',                \n",
    "                            quotechar='\"',                \n",
    "                            quoting=csv.QUOTE_NONNUMERIC, \n",
    "                            fieldnames=fieldnames\n",
    "                            )\n",
    "    writer.writeheader()                                  \n",
    "    for row in song_data:\n",
    "        writer.writerow({k:v for k,v in row.items() if k in fieldnames})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a178aaf",
   "metadata": {},
   "source": [
    "## Optional: Creating a Dataframe from the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cfbb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('songs.csv') \n",
    "#dataset = dataset.dropna()\n",
    "#dataset['album release'] = dataset['album release'].astype(int)\n",
    "#dataset['lyrics'] = dataset['lyrics'].astype('string')\n",
    "dataset\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
