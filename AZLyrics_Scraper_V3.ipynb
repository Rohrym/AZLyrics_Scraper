{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7eb1f1f",
   "metadata": {},
   "source": [
    "# AZLyrics Scraper\n",
    "\n",
    "With this code you could scrape individual lyrics pages or whole artist pages for some of their basic data. This information will be saved in a csv file. To retrieve the data of the artist/band you want, you need to change the following link within the quotation markts with that of the AZLyrics artist page (make sure you use the full link). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "554a98f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_url = 'https://www.azlyrics.com/l/larkinpoe.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa93ceb",
   "metadata": {},
   "source": [
    "## Setting up\n",
    "\n",
    "First we start by importing various python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a20aa346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d57df9",
   "metadata": {},
   "source": [
    "Then we make functions to retrieve the urls from the web and look for certain elements within the webpages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7599e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_page(url):\n",
    "    with requests.get(url) as f:\n",
    "        page = f.text\n",
    "    return page\n",
    "\n",
    "def get_element_text(element):\n",
    "    try:\n",
    "        return element.text.strip()\n",
    "    except AttributeError as e:                     \n",
    "        print('Element not found, error: {}'.format(e), file=sys.stderr)\n",
    "        return ''\n",
    "\n",
    "def get_genre_element(html):\n",
    "    try:\n",
    "        genre_script = html.find('body').find_all('script')[2]\n",
    "        genre = str(genre_script).split()[9][1:-2]\n",
    "        return genre\n",
    "    except AttributeError as e:                     \n",
    "        print('Element not found, error: {}'.format(e), file=sys.stderr)\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccfc0b3",
   "metadata": {},
   "source": [
    "## Getting the individual lyrics\n",
    "We proceed to make a function to get the basic information from each song on a songpage from AZLyrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84924e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_song_info(url):\n",
    "    song_page = BeautifulSoup(load_page(url), 'lxml')                  \n",
    "    interesting_html = song_page.find(class_='container main-page')    \n",
    "    if not interesting_html:\n",
    "        print('No information availible for song at {}'.format(url), file=sys.stderr)\n",
    "        return {}                                                      \n",
    "    album = get_element_text(interesting_html.find(class_='songinalbum_title').find('b'))[1:-1]\n",
    "    album_released = get_element_text(interesting_html.find(class_='songinalbum_title'))[-5:-1]\n",
    "    credits = get_element_text(interesting_html.find_all(class_='smt')[2])[11:]\n",
    "    genre = get_genre_element(song_page)\n",
    "    lyrics = get_element_text(interesting_html.find('div', {'class':None}))\n",
    "    return {'album': album, 'album release': album_released,'credits': credits, 'genre': genre, 'lyrics': lyrics}                      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd14e23d",
   "metadata": {},
   "source": [
    "## Getting all artist songs\n",
    "\n",
    "Now that we are able to get the basic information of each song we now need to define a function to look over the table containing all the songs from the artist and extract the song title and the associated link. The links will be important as it will allow us to loop over the songs and retrieve them one by one using the previous function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09e06fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_songs(url):\n",
    "    index_page = BeautifulSoup(load_page(url), 'lxml')        \n",
    "    items = index_page.find(id=\"listAlbum\")                   \n",
    "    if not items:                                             \n",
    "        print('Something went wrong!', file=sys.stderr)\n",
    "        sys.exit()\n",
    "    data = []\n",
    "    for row in items.find_all(class_= 'listalbum-item'):          \n",
    "        song = get_element_text(row.find('a'))\n",
    "        link = row.find('a').get('href')\n",
    "        link = 'https://www.azlyrics.com/' + str(link)\n",
    "        data.append({    \n",
    "                         'song': song,\n",
    "                         'link': link,\n",
    "                        })\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55a24f3",
   "metadata": {},
   "source": [
    "## Scraping\n",
    "\n",
    "The following code scrapes AZLyrics for the data for all the given artist's songs. This may take a while depending on the amount of songs released by the artist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c49b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping info on Long Hard Fall.\n",
      "Scraping info on We Intertwine.\n",
      "Scraping info on Burglary.\n",
      "Scraping info on To Myself.\n",
      "Scraping info on Shadows Of Ourselves.\n",
      "Scraping info on The Principle Of Silver Lining.\n",
      "Scraping info on Ball And Chain.\n",
      "Scraping info on Nothin' But Air.\n",
      "Scraping info on Fairbanks, Alaska.\n",
      "Scraping info on Praying For The Bell.\n",
      "Scraping info on Sea Song.\n",
      "Scraping info on Wrestling A Stranger.\n",
      "Scraping info on Natalie.\n",
      "Scraping info on Enough For You.\n",
      "Scraping info on By The Pier.\n",
      "Scraping info on In My Time Of Dying (Live).\n",
      "Scraping info on Principle Of Silver Lining (Live).\n",
      "Scraping info on Teardrop (Live).\n",
      "Scraping info on I Belong To Love.\n",
      "Scraping info on Leave.\n",
      "Scraping info on I Can Almost.\n",
      "Scraping info on Tired.\n",
      "Scraping info on As Good As You.\n",
      "Scraping info on Missing Home.\n",
      "Scraping info on Wait For Me.\n",
      "Scraping info on Widow's Walk.\n",
      "Scraping info on Jailbreak.\n",
      "Scraping info on Don't.\n",
      "Scraping info on Stubborn Love.\n",
      "Scraping info on Dandelion.\n",
      "Scraping info on Crown Of Fire.\n",
      "Scraping info on Elephant.\n",
      "Scraping info on High Horse.\n",
      "Scraping info on Sugar High.\n",
      "Scraping info on Jesse.\n",
      "Scraping info on Banks Of Allatoona.\n",
      "Scraping info on We Intertwine.\n",
      "Scraping info on Overachiever.\n",
      "Scraping info on Sucker Puncher.\n",
      "Scraping info on Trouble In Mind.\n",
      "Scraping info on Don't.\n",
      "Scraping info on When God Closes A Door.\n",
      "Scraping info on P-R-O-B-L-E-M.\n",
      "Scraping info on Stubborn Love.\n",
      "Scraping info on Jailbreak.\n",
      "Scraping info on Banks Of Allatoona.\n",
      "Scraping info on Blunt.\n",
      "Scraping info on Sugar High.\n",
      "Scraping info on Crown Of Fire.\n",
      "Scraping info on Overachiever.\n",
      "Scraping info on Come On In My Kitchen.\n",
      "Scraping info on Freedom.\n",
      "Scraping info on Black Betty.\n",
      "Scraping info on Look Away.\n",
      "Scraping info on Preachin' Blues.\n",
      "Scraping info on Cast 'Em Out.\n",
      "Scraping info on Pink & Red.\n",
      "Scraping info on John The Revelator.\n",
      "Scraping info on Wanted Woman / AC/DC.\n",
      "Scraping info on Tom Devil.\n"
     ]
    }
   ],
   "source": [
    "song_data = get_songs(index_url)                      \n",
    "for row in song_data:\n",
    "    print('Scraping info on {}.'.format(row['song'])) #can be useful for debugging\n",
    "    url = row['link']\n",
    "    song_info = get_song_info(url)                    \n",
    "    for key, value in song_info.items():\n",
    "        row[key] = value\n",
    "    time.sleep(random.uniform(3,8)) #take this faster code if you have <100 songs you want to download\n",
    "    #time.sleep(random.uniform(4,16)) #take this slower code if you have >100 songs you want to download\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8942ff6",
   "metadata": {},
   "source": [
    "## Writing data into CSV\n",
    "\n",
    "In this last part we will write down the data we have just scraped in a csv file and convert it to a table using the pandas module in python. From this dataframe we could acces the data easily and perform operations on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55188219",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = index_url.rsplit('/', 1)[1][:-5]\n",
    "with open(filename, 'w', encoding='utf-8') as f:       \n",
    "    fieldnames=['song', 'album', 'album release', 'genre','credits', 'lyrics']\n",
    "    writer = csv.DictWriter(f,\n",
    "                            delimiter=',',                \n",
    "                            quotechar='\"',                \n",
    "                            quoting=csv.QUOTE_NONNUMERIC, \n",
    "                            fieldnames=fieldnames\n",
    "                            )\n",
    "    writer.writeheader()                                  \n",
    "    for row in song_data:\n",
    "        writer.writerow({k:v for k,v in row.items() if k in fieldnames})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a178aaf",
   "metadata": {},
   "source": [
    "## Optional: Creating a Dataframe from the CSV file\n",
    "\n",
    "This allows you to see what is in the csv file from this Juypiter Notebook and do operations on the data if so desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7cfbb7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>album</th>\n",
       "      <th>album release</th>\n",
       "      <th>genre</th>\n",
       "      <th>credits</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Long Hard Fall</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2010</td>\n",
       "      <td>pop</td>\n",
       "      <td></td>\n",
       "      <td>And me, I cried when I told the truth\r\n",
       "I cried...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We Intertwine</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2010</td>\n",
       "      <td>pop</td>\n",
       "      <td>Rebecca Anne Lovell, Megan Lovell</td>\n",
       "      <td>As the cold turns to frost and the day becomes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Burglary</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2010</td>\n",
       "      <td>pop</td>\n",
       "      <td></td>\n",
       "      <td>I never meant to be your mark\r\n",
       "I never meant t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To Myself</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2010</td>\n",
       "      <td>pop</td>\n",
       "      <td></td>\n",
       "      <td>What good could come from a world gone bad\r\n",
       "He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shadows Of Ourselves</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2010</td>\n",
       "      <td>pop</td>\n",
       "      <td></td>\n",
       "      <td>Oh, warm in my bed\r\n",
       "With your head on my chest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Ramblin' Man</td>\n",
       "      <td>Kindred Spirits</td>\n",
       "      <td>2020</td>\n",
       "      <td>pop</td>\n",
       "      <td>Dickey Betts</td>\n",
       "      <td>Lord, I was born a ramblin' man\r\n",
       "Tryna make a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Bell Bottom Blues</td>\n",
       "      <td>Kindred Spirits</td>\n",
       "      <td>2020</td>\n",
       "      <td>pop</td>\n",
       "      <td>Eric Clapton</td>\n",
       "      <td>Bell bottom blues, you made me cry\r\n",
       "I don't wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Crocodile Rock</td>\n",
       "      <td>Kindred Spirits</td>\n",
       "      <td>2020</td>\n",
       "      <td>pop</td>\n",
       "      <td>Elton John, Bernie Taupin</td>\n",
       "      <td>Well, I remember when rock was young\r\n",
       "Me and S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Black Echo</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Mad As A Hatter</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    song            album  album release genre  \\\n",
       "0         Long Hard Fall           Spring           2010   pop   \n",
       "1          We Intertwine           Spring           2010   pop   \n",
       "2               Burglary           Spring           2010   pop   \n",
       "3              To Myself           Spring           2010   pop   \n",
       "4   Shadows Of Ourselves           Spring           2010   pop   \n",
       "..                   ...              ...            ...   ...   \n",
       "89          Ramblin' Man  Kindred Spirits           2020   pop   \n",
       "90     Bell Bottom Blues  Kindred Spirits           2020   pop   \n",
       "91        Crocodile Rock  Kindred Spirits           2020   pop   \n",
       "92            Black Echo                               0         \n",
       "93       Mad As A Hatter                               0         \n",
       "\n",
       "                              credits  \\\n",
       "0                                       \n",
       "1   Rebecca Anne Lovell, Megan Lovell   \n",
       "2                                       \n",
       "3                                       \n",
       "4                                       \n",
       "..                                ...   \n",
       "89                       Dickey Betts   \n",
       "90                       Eric Clapton   \n",
       "91          Elton John, Bernie Taupin   \n",
       "92                                      \n",
       "93                                      \n",
       "\n",
       "                                               lyrics  \n",
       "0   And me, I cried when I told the truth\n",
       "I cried...  \n",
       "1   As the cold turns to frost and the day becomes...  \n",
       "2   I never meant to be your mark\n",
       "I never meant t...  \n",
       "3   What good could come from a world gone bad\n",
       "He...  \n",
       "4   Oh, warm in my bed\n",
       "With your head on my chest...  \n",
       "..                                                ...  \n",
       "89  Lord, I was born a ramblin' man\n",
       "Tryna make a ...  \n",
       "90  Bell bottom blues, you made me cry\n",
       "I don't wa...  \n",
       "91  Well, I remember when rock was young\n",
       "Me and S...  \n",
       "92                                                     \n",
       "93                                                     \n",
       "\n",
       "[94 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(filename) \n",
    "for index, value in df.dtypes.items(): \n",
    "    if value == 'object':\n",
    "        df[index] = df[index].fillna('')\n",
    "    else:\n",
    "        df[index] = df[index].fillna(0)\n",
    "df['album release'] = df['album release'].astype(int)\n",
    "df['lyrics'] = df['lyrics'].astype('string')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132520c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
